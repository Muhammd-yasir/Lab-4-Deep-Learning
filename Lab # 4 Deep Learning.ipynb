{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15058bb",
   "metadata": {},
   "source": [
    "# Question No 1: Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11d41db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "416ddf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "w = tf.Variable([0.2], dtype=tf.float32)  # initial weight\n",
    "b = tf.Variable([-0.2], dtype=tf.float32)  # initial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21b290f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.0, 2.0, 3.0, 4.0])  # input\n",
    "y = tf.constant([0.0, -1.0, -2.0, -3.0])  # actual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ef7e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear model\n",
    "#linear_model = w * x + b\n",
    "def linear_model(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58c9c6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: [0.2]\n",
      "Initial bias: [-0.2]\n"
     ]
    }
   ],
   "source": [
    "# Print initial values of weight and bias\n",
    "print(\"Initial weight:\", w.numpy())\n",
    "print(\"Initial bias:\", b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e2e83d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output is:\n",
      "[0.         0.2        0.40000004 0.6       ]\n"
     ]
    }
   ],
   "source": [
    "# Print predicted output\n",
    "print(\"Predicted output is:\")\n",
    "predicted_output = linear_model(x,w,b)\n",
    "print(predicted_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44cafbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss or Error is \n",
      "20.16\n"
     ]
    }
   ],
   "source": [
    "squared_deltas = tf.square(linear_model(x,w,b) - y)  # used to square the error\n",
    "loss = tf.reduce_sum(squared_deltas) \n",
    "print(\"loss or Error is \")\n",
    "print(loss.numpy())  # evaluating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7f4b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "# Run optimization for 1000 epochs\n",
    "for i in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_output = linear_model(x, w, b)\n",
    "        loss = tf.reduce_sum(tf.square(predicted_output - y))\n",
    "    gradients = tape.gradient(loss, [w, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "20e7ca3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weight: [-0.85208464]\n",
      "Optimized bias: [0.56511086]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimized values for weight and bias\n",
    "optimized_w, optimized_b = w.numpy(), b.numpy()\n",
    "print(\"Optimized weight:\", optimized_w)\n",
    "print(\"Optimized bias:\", optimized_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c56193be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output with optimized parameters: [-0.28697377 -1.1390584  -1.991143   -2.8432276 ]\n",
      "Loss with optimized parameters: 0.1263472\n"
     ]
    }
   ],
   "source": [
    "predicted_output = linear_model(x, optimized_w, optimized_b)\n",
    "loss = tf.reduce_sum(tf.square(predicted_output - y))\n",
    "print(\"Predicted output with optimized parameters:\", predicted_output.numpy())\n",
    "print(\"Loss with optimized parameters:\", loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a1f28",
   "metadata": {},
   "source": [
    "We first tried the learning rate 0.1 but the loss after the optimizer was to high and same was the case for 0.0001. But when we used 0.001 the loss ater using the optimizer was reduced. So we used 0.001 as the best learning rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd92f77f",
   "metadata": {},
   "source": [
    "# Question no 2: Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "257d6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "040c610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "w = tf.Variable([0.2], dtype=tf.float32)  # initial weight\n",
    "b = tf.Variable([-0.2], dtype=tf.float32)  # initial bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8676f93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0])  # input\n",
    "y = tf.constant([0.0, -1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8.0, -9.0])  # actual output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42e4bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear model\n",
    "#linear_model = w * x + b\n",
    "def linear_model(x, w, b):\n",
    "    return w * x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "97929962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: [0.2]\n",
      "Initial bias: [-0.2]\n"
     ]
    }
   ],
   "source": [
    "# Print initial values of weight and bias\n",
    "print(\"Initial weight:\", w.numpy())\n",
    "print(\"Initial bias:\", b.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da90fdf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output is:\n",
      "[0.         0.2        0.40000004 0.6        0.8        1.\n",
      " 1.1999999  1.4        1.6        1.8       ]\n"
     ]
    }
   ],
   "source": [
    "# Print predicted output\n",
    "print(\"Predicted output is:\")\n",
    "predicted_output = linear_model(x,w,b)\n",
    "print(predicted_output.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "77a0737a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss or Error is \n",
      "410.40002\n"
     ]
    }
   ],
   "source": [
    "squared_deltas = tf.square(linear_model(x,w,b) - y)  # used to square the error\n",
    "loss = tf.reduce_sum(squared_deltas) \n",
    "print(\"loss or Error is \")\n",
    "print(loss.numpy())  # evaluating the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a8ed868",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "# Run optimization for 1000 epochs\n",
    "for i in range(1000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_output = linear_model(x, w, b)\n",
    "        loss = tf.reduce_sum(tf.square(predicted_output - y))\n",
    "    gradients = tape.gradient(loss, [w, b])\n",
    "    optimizer.apply_gradients(zip(gradients, [w, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ace2c2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized weight: [nan]\n",
      "Optimized bias: [nan]\n"
     ]
    }
   ],
   "source": [
    "# Get the optimized values for weight and bias\n",
    "optimized_w, optimized_b = w.numpy(), b.numpy()\n",
    "print(\"Optimized weight:\", optimized_w)\n",
    "print(\"Optimized bias:\", optimized_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c485cd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted output with optimized parameters: [nan nan nan nan nan nan nan nan nan nan]\n",
      "Loss with optimized parameters: nan\n"
     ]
    }
   ],
   "source": [
    "predicted_output = linear_model(x, optimized_w, optimized_b)\n",
    "loss = tf.reduce_sum(tf.square(predicted_output - y))\n",
    "print(\"Predicted output with optimized parameters:\", predicted_output.numpy())\n",
    "print(\"Loss with optimized parameters:\", loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdae85f",
   "metadata": {},
   "source": [
    "In this question we have expand the dataset by adding more points in X from 5 to 10 and in Y also so the loss is greater then before and after using the optimizer the loss is also to high. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
